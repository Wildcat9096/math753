{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math 753/853 HW1: Bisection and Newton search methods\n",
    "\n",
    "## Before you begin!\n",
    "\n",
    "**First rename this file \"math753-hw1-mylastname\"** using your last name in the indicated spot. With the file extension, the full filename should be \"math753-hw1-mylastname.ipynb\". No capital letters, please. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.\n",
    "\n",
    "Write a Julia function `bisectsearch` that takes a function $f(x)$ and an interval $a,b$ for which $f(a)$ and $f(b)$ have opposite signs, and returns a root of $f$ within that interval. \n",
    "\n",
    "**Hints:**\n",
    "\n",
    "  * While writing your `bisectsearch` function, test it on a simple function whose root you know, for example $f(x) = x^2 - 4$, which has the root $x=2$. \n",
    "  \n",
    "  \n",
    "  \n",
    "  * You're likely to make mistakes in your first attempt at any algorithm. To help you find and fix errors, add some diagnostic printing to your function that prints out $a, b$, and $f(c)$ at each iteration. Add an optional argument `diagnostics` to the function that turns the printing on and off. Make `diagnostics` default to `false`.\n",
    "  \n",
    "  \n",
    "  \n",
    "  * While developing your function, use a simple and sure stopping condition, for example, iterating a fixed number of times, perhaps ten or twenty. \n",
    "  \n",
    "  \n",
    "  \n",
    "  * Store the values of `f(a)` and `f(b)` in temporary variables, e.g. `fa, fb = f(a), f(b)`, rather than evaluating these quantities repeatedly for the same values of `a` and `b`. In real-world applications, evaluating `f` is expensive, so you want to minimize the number of function evaluations!\n",
    "\n",
    "\n",
    "\n",
    "  * Once you've got the logic of bisection working correctly, make sure it works for any floating-point type, and change the stopping condition to ensure an appropriate level of accuracy for the given floating point type. I suggest stopping the search when either $(b-a)/(|a| + |b|) < 10 \\, \\epsilon$ or $|f(c)| < 10 \\, \\epsilon$, where $\\epsilon$ is the *machine precision* of the given floating-point type. The Julia code `eps(typeof(x))` returns the machine precision for the type of variable `x`. It's probably safest to get $\\epsilon$ using the type of `c=(a+b)/2`. Why?\n",
    " \n",
    "  \n",
    "  \n",
    "  * Add checks to your `bisectsearch` function that verify that the starting conditions for bisection search are met. The checks should print a helpful error message and exit the function while returning the most reasonable value for the root from available information. \n",
    "\n",
    "\n",
    "\n",
    "  * At first using `if-else` statements is probably simplest, but using short-circuit conditionals keeps the code short and readable.\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bisectsearch (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function bisectsearch(f, a, b)\n",
    "    \n",
    "    # write a bisection algorithm here! \n",
    "    # the function should return a root of f\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Apply the bisection search algorithm to find all real roots of the following equations. After you have a root $x$, check the value of $f(x)$. It should be zero or very nearly zero. \n",
    "\n",
    "**Hints for Problem 2:**\n",
    "\n",
    "  * Rewrite each equation in the form $f(x) = 0$, then find the roots of $f$. \n",
    "  \n",
    "  \n",
    "  * To find a bracket $a, b$ of the root, plot $f(x)$ versus $x$ and find an interval where it crosses zero.\n",
    "  \n",
    "  \n",
    "  * It's probably best to use different function names, $f(x), g(x),$ and $h(x)$ for (a), (b), and (c). Or use anonymous function syntax, e.g. `x = bisectsearch(x -> 3x^3 + x^2 - x - 5, 0, 2)`.\n",
    "  \n",
    "\n",
    "(a) $3x^3 + x^2 = x + 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) $\\cos^2 x + 6 = x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) $x^3 - 2x^2 + 4x/3 = 8/27$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Write a Julia function `newtonsearch` that take a function $f(x)$ and an initial guess $x$, and returns a root $r$ of $f$ using the Newton method. Find the root to an accuracy appropriate for the floating-point type of the initial guess $x$. \n",
    "\n",
    "\n",
    "**Hints** \n",
    "\n",
    "  * Unlike bisection, which is guaranteed to converge, the Newton method can go haywire. Think of a good way to test if the Newton method is failing, and print an error message and exit in this case. Your function should still return a number of the same floating-point type as $x_0$. In Julia, this is known as  [type stability](http://www.johnmyleswhite.com/notebook/2013/12/06/writing-type-stable-code-in-julia).\n",
    "\n",
    "\n",
    "  * All the hints for Problem 1 apply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 \n",
    "\n",
    "Apply the Newton method to find all real roots of\n",
    "\n",
    "(a) $3x^3 + x^2 = x + 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) $\\cos^2 x + 6 = x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) $x^3 - 2x^2 + 4x/3 = 8/27$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Modify your bisection-search and Newton-method functions so that, along with the root $r$ they return a vector of errors $e_n = | x_n - r|$ for $n=1,2,...$. Then solve $\\cos^2 x + 6 = x$ using both bisection and Newton method, and make a plot comparing $e_n$ versus $n$ for the two methods. Put both the bisection errors and the Newton method errors on the same plot. Use blue circles for bisection errors and red squares for Newton method. Make the vertical $e_n$ axis logarithmic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have theoretical estimates of the convergence rates of bisection and Newton method. Do your error plots fit this theory, or not? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Your results for (c) in problems 2 and 4 might be a little unexpected or strange. Describe any weirdness you notice. Do you have any ideas for what might be causing this strange behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus problems! \n",
    "\n",
    "Bonus problems are extra challenges for those who just can't get enough numerical mathematics! \n",
    "\n",
    "## Bonus problem 7\n",
    "\n",
    "Use your Newton-method function to find the root of $f(x) = x^2$ starting with initial guess $x_0=1$, and plot the error $e_n$ versus $n$ as in problem 5. Does the Newton method converegence toward the true solution at the expected rate? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus problem 8\n",
    "\n",
    "Consider\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x) = \\left(1 - \\frac{3}{4x}\\right)^{1/3}\n",
    "\\end{equation*}\n",
    "\n",
    "What is the root $r$ of this function? What happens when you apply your Newton search algorithm to this function with a starting guess $x_0 = 1$? Why?\n",
    "\n",
    "Is it possible to find the root of this function using Newton search? How?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
